{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f9970e-59b1-470d-a3a4-15ff234ade22",
   "metadata": {},
   "source": [
    "# Pré-traitement des données d'entrée du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234b679-38f8-4c78-a610-f3d56a942a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18198a5-b6b0-4349-8f8c-6107b64916e9",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa3d5e-7429-4a29-8725-8bfd080d839f",
   "metadata": {},
   "source": [
    "Certains modèles font des hypothèses sur la distribution des données d'entrée. En particulier ils peuvent supposer que la variance de toutes les variables sont du même ordre de grandeur pour fonctionner correctement.  \n",
    "C'est en particulier le cas des machines à vecteurs de support (*support vector machines* ou SVM) qui seront utilisées dans cette section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b463c-3200-41b8-b84b-a8246dd4f9f8",
   "metadata": {},
   "source": [
    "Les données support de cette partie sont des mesures réalisées sur des tumeurs afin de détecter un éventuel cancer du sein.  \n",
    "La description du jeu de données est fournie dans l'élément `DESCR` du dictionnaire (`data`).  \n",
    "En particulier, cette description donnes des informations de dispersion des mesures (le min et le max pour chaque variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f11e81-bb27-4af7-b4c5-498b2a26d470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "X_np, y = data.data, data.target_names[data.target]\n",
    "X = pd.DataFrame(X_np, columns=data[\"feature_names\"])\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e1e67-6a92-4604-988f-166dba41aa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb26a37-3a1a-439a-9f92-ee6ef113b4a1",
   "metadata": {},
   "source": [
    "Comme souvent en apprentissage automatique, le jeu de données annoté est séparé en deux : un jeu de données d'entrainement (75%) et un jeu de données de validation (25%), servant à évaluer le pouvoir prédictif du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3d941-66eb-40e5-b955-cd7a56ce6383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb781852-7c68-45f0-a670-f99d676b62e4",
   "metadata": {},
   "source": [
    "**Question** : Entraîner un classificateur à vecteurs de support ([classe `SVC` de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)) sur le jeu de données d'entraînement, puis afficher les deux matrices de confusion : une pour les données de test et une pour les données d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8afe96-e1f4-4b7d-a8b8-d2ffec461ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Éventuellement pour vous simplifier la vie, il n'est pas obligatoire d'utiliser cette fonction.\n",
    "def plot_confusion_matrix(y_test_true, y_test_pred, y_train_true, y_train_pred):\n",
    "    \"\"\"Display confusion matrices side-by-side.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n",
    "    for y_true, y_pred, ax, title in [\n",
    "        (y_test_true, y_test_pred, ax1, \"Test data\"),\n",
    "        (y_train_true, y_train_pred, ax2, \"Train data\"),\n",
    "    ]:\n",
    "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, ax=ax)\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fdbcc7-c598-4f77-8d04-0f1ea083a092",
   "metadata": {},
   "source": [
    "Nous allons ensuite tenter d'améliorer la performance du modèle en normalisant les données d'entrée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa128b-fe0c-4530-bfea-869392f96c0b",
   "metadata": {},
   "source": [
    "**Question** : Est-il souhaitable de réaliser cette normalisation sur l'ensemble du jeu de données original ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7056f33-1a9b-4d7d-8671-0174ad44aeb1",
   "metadata": {},
   "source": [
    "**Question** : Réaliser une transformation des données d'entrée pour les mettre à une échelle [0, 1] ([classe `MinMaxScaler` de scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892f248-54c9-4da9-9220-b7958f95cdcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4bcfa-d470-4d0d-8618-e62c0e271a58",
   "metadata": {},
   "source": [
    "**Question** : Quelles sont les plages de valeurs des données d'entrainement transformées ?  \n",
    "Sont-elles dans l'intervalle [0, 1] ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c6f93-d242-48e7-adb8-b77b58418556",
   "metadata": {},
   "source": [
    "**Question** : Quelles sont les plages de valeurs des données de test transformées ?  \n",
    "Sont-elles dans l'intervalle [0, 1] ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eca422-d2e4-4342-abd1-1ec9228557c8",
   "metadata": {},
   "source": [
    "**Question** : Réaliser un nouvel entraînement sur les données transformées et afficher les matrices de confusion correspondantes.  \n",
    "Le résultat a-t-il changé par rapport au modèle précédent, entraîné sur les données brutes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19245968-56a7-401e-87f3-1e81a07bc6cb",
   "metadata": {},
   "source": [
    "**Question** Reprendre les quatre questions précédentes en limitant les valeurs de sortie du prétraitement : `MinMaxScaler(clip=True)`.  \n",
    "Cette modification a-t-elle un impact sur la précision du modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3200db-29b0-44c3-8693-62abc398074d",
   "metadata": {},
   "source": [
    "## Séquences de traitements (*pipelines*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6039a5-2ae7-4c8f-a399-fddba3066190",
   "metadata": {},
   "source": [
    "Dans la section précédente, nous avons réalisé une partie des prétraitements sur le jeu d'entraînement (`fit` et `transform`) et une autre sur le jeu de validation (`transform` uniquement), puis la même chose pour le classificateur (`fit` et `predict`, ou uniquement `predict`). Avec scikit-learn, il est possible de définir des [séquences de traitements](https://scikit-learn.org/stable/modules/compose.html) dont l'entraînement est ensuite commun.  \n",
    "Cela permet en particulier d'éviter que des informations statistiques issues des données de test ne soient utilisées pour l'entraînement. Ce sera particulièrement utile dans la suite du cours pour réaliser une validation croisée ou optimiser les hyper-paramètres d'un modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de9650-89cb-47d5-b144-48e7554f4950",
   "metadata": {},
   "source": [
    "**Question** : Définir une pipeline intégrant la normalisation et la classification, puis vérifier que vous obteniez bien les mêmes résultats que précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68eac39-fe39-46fc-ab10-63afc3c4f286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b692dc-1b48-4012-9a2d-7ef826387291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('classifier', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf8051-5dff-4406-a023-ec88f7a26ef5",
   "metadata": {},
   "source": [
    "**Question** : Vérifier que la standardisation ne s'est bien basée que sur les données d'entraînement.  \n",
    "Pour cela, il est possible d'extraire un estimateur correspondant à une sous-chaîne de traitement. Ici, on prendra l'unique étape de prétraitement, c'est-à-dire `pipeline[0]`, ou, plus généralement, `pipeline[:-1]` (toutes les étapes sauf la dernière)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48017447-b0e9-4da8-9479-6f3a0eda01d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessing = pipeline[:-1]\n",
    "preprocessing.transform(X_test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e593e-18ec-4fae-9043-bbf8c83e73f3",
   "metadata": {},
   "source": [
    "## Gestion des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e733d4-ce0c-4b8e-9935-a546d3183f13",
   "metadata": {},
   "source": [
    "Votre assistant a malencontreusement perdu les mesures de valeur moyenne et de pire tumeur pour un quart des patients (il ne lui reste que les mesures d'écart type, soit un tiers des variables d'entrée)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c036cc2-d39a-4a4c-b3f8-74bd2f028047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_cols = [col for col in X.columns if \"mean\" in col or \"worst\" in col]\n",
    "print(f\"Deleted columns: {missing_cols} ({len(missing_cols)/len(X.columns):.2%} of features)\")\n",
    "X_missing = X.copy()\n",
    "missing_idx = X_missing.sample(frac=0.25).index\n",
    "X_missing.loc[missing_idx, missing_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435248df-09a2-49ec-9ac5-e3de246043e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_missing.iloc[:, :15].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21ff72-bed0-4e71-a6ab-a00b91f6b4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_m, X_test_m, y_train, y_test = train_test_split(X_missing, y, random_state=123)\n",
    "print(f\"{len(set(X_train_m.index).intersection(missing_idx))/len(X_train_m):.2%} of the train dataset has missing values, \"\n",
    "      f\"{len(set(X_test_m.index).intersection(missing_idx))/len(X_test_m):.2%} of the test dataset has missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157fc56d-6b20-4e96-9922-8cb5556d2808",
   "metadata": {},
   "source": [
    "La grande majorité des modèles de scikit-learn ne supportent pas les valeurs manquantes (comme généralement en apprentissage automatique).  \n",
    "**Question** : Vérifier si votre chaîne de traitement est compatible avec les nouvelles données d'entrée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c68e60e-7d0a-4bd1-9dfb-0d18e89a7f34",
   "metadata": {},
   "source": [
    "**Question** : Définir une nouvelle chaine de traitements permettant de prendre en compte l'absence de valeurs renseignées.  \n",
    "Vous avez pour cela trois grands types de stratégies :\n",
    "- ignorer les colonnes en question (pour appliquer des traitements spécifiques à des colonnes, vous pouvez utiliser [la classe `ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html))\n",
    "- remplacer les valeurs manquantes par des valeurs typiques (voir [la classe `SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer))\n",
    "- remplacer les valeurs manquantes par des valeurs estimées par un autre modèle (par exemple, en se basant sur les [mesures les plus proches](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f9c51-ab9f-4b9d-a574-7b532b325589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3b68f-1cc4-46ef-96d9-3fa215ea0014",
   "metadata": {},
   "source": [
    "## Données catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d4090-154e-4f2c-bdde-d44e64a30cee",
   "metadata": {},
   "source": [
    "Les modèles d'apprentissage automatique attendent en entrée des vecteurs numériques de taille fixe. Il est donc nécessaire de transformer les entrées catégorielles, surtout si elles sont représentées par des chaînes de caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff0830-ded0-497a-a8f3-7790035119db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\"pets\": [\"dog\", \"cat\", \"snake\", \"dog\", \"goldfish\", \"dog\"]})\n",
    "X_train = X[:4]\n",
    "X_test = X[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020ea89-8109-4da5-8718-375003cf7e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(X_train)\n",
    "display(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48c705-bb55-4c5f-bf4c-afd1e156abb6",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d17d13-836d-45d1-8ea9-5574d9fe3a12",
   "metadata": {},
   "source": [
    "Une manière de réaliser ce type de transformation consiste à générer autant de variables booléennes qu'il existe de catégories. On obtient donc en sortie du traitement, pour *n* catégories, un vecteur de taille *n*, avec la valeur 1 pour la colonne correspondant à la catégorie de l'observation et 0 partout ailleurs.  \n",
    "Cette transformation est désignée comme un encodage un parmi n, ou *one-hot encoding* en anglais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6ce4a-f62c-4118-b655-5b8222ed3941",
   "metadata": {},
   "source": [
    "La bibliothèque pandas propose [la méthode `get_dummies`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) pour réaliser ce type de traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62823c4-81d3-4cf0-a6f6-34c08390e1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b694912-a09f-44d0-b186-640eb283d081",
   "metadata": {},
   "source": [
    "**Question** : Pourquoi n'est-il pas correct de réaliser ce type de prétraitement globalement ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c20a9-ee0a-4b9c-9d2a-5e433549af1d",
   "metadata": {},
   "source": [
    "**Question** : Utiliser [la classe `OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) (avec, entre autres, l'option `sparse_output=False`) pour réaliser le prétraitement.  \n",
    "Visualiser les données d'entrainement et de test après transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c91845-ac3e-4e40-95e4-1f948abb7e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741f7ac-48ae-44e9-a3a8-05ddc6550841",
   "metadata": {},
   "source": [
    "### Ordinal encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25689e9-a668-4a22-bf0d-6a5a43d469b0",
   "metadata": {},
   "source": [
    "Pour transformer les valeurs catégorielles en valeurs numériques, il est aussi possible de passer par une représentation entière, discrète elle aussi, à l'aide de [la classe `OrdinalEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html).  \n",
    "Attention cependant à son utilisation, car de nombreux modèles vont alors supposer qu'il existe un ordre intrinsèque aux catégories, ce qui peut dégrader significativement leur performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8134b645-28fd-4668-975f-c60c2d10c2e3",
   "metadata": {},
   "source": [
    "**Question** : Réaliser un encodage ordinal des données catégorielles et visualiser les données après transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182e5e2-ba65-4e93-a281-a943a040a4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c17cf7-3456-4b4a-8c7e-790783180a16",
   "metadata": {},
   "source": [
    "### MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdfab48-956e-42ff-95c7-a8b9ffdf05ad",
   "metadata": {},
   "source": [
    "Dans certains cas, les catégories peuvent ne pas avoir de valeur unique. C'est-à-dire que chaque observation peut être associée à zéro, une ou plusieurs catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76416d7-81c1-46c2-9c1a-f9f3836dea6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\"pets\": [{\"cat\", \"dog\"}, {\"cat\"}, {\"snake\", \"dog\"}, {\"unicorn\", \"cat\"}, {\"goldfish\"}, {\"cat\", \"dog\", \"snake\"}]})\n",
    "X_train = X[:3]\n",
    "X_test = X[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93620107-1669-44b5-a886-da28df8ce7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(X_train)\n",
    "display(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7690df2-cffb-40a0-9053-147c2aff4e7b",
   "metadata": {},
   "source": [
    "**Question** : Donner (sans automatiser le traitement) un exemple de résultat attendu après transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bd8893-8f2a-47f4-a8b1-91adaadb2d6c",
   "metadata": {},
   "source": [
    "Scikit-learn n'intègre pas directement d'outil permettant de réaliser ce type de transformation sur les entrées du modèle.  \n",
    "La transformation la plus proche est un traitement réalisé sur du texte à l'aide de [la classe `CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), où le nombre d'occurrences de chaque mot est compté.  \n",
    "Il existe quelques différences notables par rapport aux transformations utilisées jusqu'à présent :\n",
    "- `CountVectorizer` n'accepte qu'une seule colonne en entrée.\n",
    "- La sortie est une matrice creuse ([*sparse* de scipy](https://docs.scipy.org/doc/scipy/reference/sparse.html)), qui doit être convertie en matrice dense à l'aide de la méthode `todense` pour être compatible avec pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac850c-70fe-4c1c-a52b-3741ba717d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40210d1-cc00-48d0-bdd0-93804d2fd95e",
   "metadata": {},
   "source": [
    "Alternativement, il est (relativement) facile de définir vos propres classes de transformation compatibles avec scikit-learn.\n",
    "\n",
    "**Question** : Implémenter un transformateur permettant de convertir des listes de catégories en matrices binaires indiquant la présence ou non de chaque catégorie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d361c-4125-4da0-b669-6c95d1cd4d88",
   "metadata": {},
   "source": [
    "## Génération d'entrées complémentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d7371-ba30-4845-b20d-ee8136ba8096",
   "metadata": {},
   "source": [
    "Il est possible d'utiliser les transformateurs pour générer des entrées complémentaires. En particulier, scikit-learn n'intègre pas de régression polynomiale, car il est possible d'arriver au même résultat par prétraitement des entrées.  \n",
    "Dans cette section, nous allons chercher à modéliser des données générées par un polynôme d'ordre deux (avec une seule dimension ici pour simplifier la visualisation, mais cela s'applique aussi à plusieurs dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9a245-b09d-4780-bc13-16a4e586ddb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.random.uniform(size=100)\n",
    "y = 3 - (X - 0.2)**2 + np.random.normal(scale=0.02, size=100)\n",
    "X = X.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fe346-4262-412c-b127-82fa61ae0515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, label=\"train\")\n",
    "plt.scatter(X_test, y_test, label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b621295-c3cb-4e9c-bd79-70b812909aaf",
   "metadata": {},
   "source": [
    "**Question** : Utiliser un modèle de régression linéaire (voir [la classe `LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)) pour ce problème de régression.  \n",
    "Visualiser les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f39dd3f-ce50-4076-8ea5-7b30e15a4501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481998c6-ca71-4bc8-bf88-560481ec4203",
   "metadata": {},
   "source": [
    "**Question** : Utiliser [la classe `PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) pour générer des combinaisons polynomiales, de degré 2 ou plus, des entrées.  \n",
    "Visualiser les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53c66ed-dcc6-4fab-aa7c-f0d839503fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ab20c-b361-45c3-a1db-05f114825b30",
   "metadata": {},
   "source": [
    "## Pipelines ou non ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f05fc3-e78f-4975-8286-da90444a2fff",
   "metadata": {},
   "source": [
    "**Question** : Parmi toutes les transformations vues dans ce TD, lesquelles peuvent être appliquées au préalable sur l'ensemble du jeu de données ? Pourquoi ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
